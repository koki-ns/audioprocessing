{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 62081)\n",
      "norm_source_locations:\n",
      " [[[0.65272756]]\n",
      "\n",
      " [[0.53263298]]\n",
      "\n",
      " [[0.53874747]]] \n",
      "\n",
      "mic_alignments:\n",
      " [[[5.16640523 5.18640523]]\n",
      "\n",
      " [[5.04001572 5.04001572]]\n",
      "\n",
      " [[5.0978738  5.0978738 ]]]\n"
     ]
    }
   ],
   "source": [
    "import wave as wave\n",
    "import numpy as np\n",
    "import pyroomacoustics as pa\n",
    "import scipy.signal as sp\n",
    "\n",
    "def calculate_steering_vector(mic_alignments, source_locations, freqs, sound_speed=340, is_use_far=True):\n",
    "    n_channels = np.shape(mic_alignments)\n",
    "\n",
    "    n_sources = np.shape(source_locations)\n",
    "\n",
    "    if is_use_far == True:\n",
    "        norm_source_locations = source_locations/np.linalg.norm(source_locations, 2, axis=0, keepdims=True)\n",
    "        # numpyの機能で自動で計算する次元を合わせてくれる？らしい\n",
    "        # アインシュタインの縮約記法を理解する必要あり\n",
    "        # あらかた理解したが下の計算は何をやってるのか理解できない、、、\n",
    "\n",
    "        print(\"norm_source_locations:\\n\", norm_source_locations[..., None], \"\\n\")\n",
    "        print(\"mic_alignments:\\n\", mic_alignments[:, None, :])\n",
    "\n",
    "        steering_phase = np.einsum('k,ism,ism->ksm', 2.j*np.pi/sound_speed*freqs, norm_source_locations[..., None], mic_alignments[:, None, :])\n",
    "        steering_vector = 1./np.sqrt(n_channels)*np.exp(steering_phase)\n",
    "\n",
    "        return steering_vector\n",
    "\n",
    "        # steering_phase_2 = np.einsum('k,ism,ims->ksm', 2.j*np.pi/sound_speed*freqs, norm_source_locations[..., None], mic_alignments[:, None, :])\n",
    "        # steering_vector_2 =1./np.sqrt(n_channels)*np.exp(steering_phase_2)\n",
    "\n",
    "        # return([steering_vector, steering_phase_2])\n",
    "\n",
    "#2バイトに変換してファイルに保存\n",
    "#signal: time-domain 1d array (float)\n",
    "#file_name: 出力先のファイル名\n",
    "#sample_rate: サンプリングレート\n",
    "def write_file_from_time_signal(signal,file_name,sample_rate):\n",
    "    #2バイトのデータに変換\n",
    "    signal=signal.astype(np.int16)\n",
    "\n",
    "    #waveファイルに書き込む\n",
    "    wave_out = wave.open(file_name, 'w')\n",
    "\n",
    "    #モノラル:1、ステレオ:2\n",
    "    wave_out.setnchannels(1)\n",
    "\n",
    "    #サンプルサイズ2byte\n",
    "    wave_out.setsampwidth(2)\n",
    "\n",
    "    #サンプリング周波数\n",
    "    wave_out.setframerate(sample_rate)\n",
    "\n",
    "    #データを書き込み\n",
    "    wave_out.writeframes(signal)\n",
    "\n",
    "    #ファイルを閉じる\n",
    "    wave_out.close()\n",
    "\n",
    "\n",
    "# 遅延和アレイの実験コード\n",
    "np.random.seed(0)\n",
    "\n",
    "clean_wave_files=[\"./CMU_ARCTIC/cmu_us_aew_arctic/wav/arctic_a0001.wav\"]\n",
    "\n",
    "n_sources = len(clean_wave_files)\n",
    "\n",
    "n_samples = 0\n",
    "\n",
    "\n",
    "# 最小のフレーム数を取得\n",
    "for clean_wave_file in clean_wave_files:\n",
    "    wav = wave.open(clean_wave_file)\n",
    "    if n_samples < wav.getnframes():\n",
    "        n_samples = wav.getnframes()\n",
    "    wav.close()\n",
    "\n",
    "clean_data = np.zeros([n_sources, n_samples])\n",
    "\n",
    "s = 0\n",
    "# ファイルを開いているが、マルチチャンネル（複数マイクで収録した音）はどのように処理されているのか？wavに対する関数の処理を含めて調べる必要がある\n",
    "for clean_wave_file in clean_wave_files:\n",
    "    wav = wave.open(clean_wave_file)\n",
    "    data = wav.readframes(wav.getnframes())\n",
    "    data = np.frombuffer(data, dtype=np.int16)\n",
    "    data = data/np.iinfo(np.int16).max\n",
    "    clean_data[s, :wav.getnframes()] = data\n",
    "    wav.close()\n",
    "    s = s + 1\n",
    "\n",
    "#----------シミュレーションのパラメータ--------------\n",
    "\n",
    "# サンプリング周波数\n",
    "sample_rate = 16000\n",
    "\n",
    "# フレームサイズ\n",
    "N = 1024\n",
    "\n",
    "# 周波数の数\n",
    "Nk = N/2 + 1\n",
    "\n",
    "# 各ビンの周波数\n",
    "freqs = np.arange(0, Nk, 1) * sample_rate / N\n",
    "\n",
    "# 音声と雑音との比率 [dB]\n",
    "SNR = 20.\n",
    "\n",
    "# 部屋の大きさ\n",
    "room_dim = np.r_[10.0, 10.0, 10.0]\n",
    "\n",
    "# マイクロホンアレイを置く部屋の場所\n",
    "mic_array_loc = room_dim / 2 + np.random.randn(3) * 0.1\n",
    "\n",
    "\"\"\"\n",
    "部屋の大きさやマイクロホン位置等は音声データをシミュレーション上で生成するために設定しているものっぽい\n",
    "つまり、実データではマイクロホン座標を原点として、各方向のステアリングベクトルをスキャンすればOK?\n",
    "\"\"\"\n",
    "\n",
    "# マイクロホンアレイのマイクロホン配置\n",
    "mic_alignments = np.array(\n",
    "    [\n",
    "        [-0.01, 0.0, 0.0],\n",
    "        [0.01, 0.0, 0.0],\n",
    "    ]\n",
    ")\n",
    "\n",
    "# マイクロホン数\n",
    "n_channels = np.shape(mic_alignments)[0]\n",
    "\n",
    "# get the microphone array\n",
    "R = mic_alignments .T + mic_array_loc[:, None]\n",
    "\n",
    "#------------------------------------------------\n",
    "\n",
    "# 部屋を生成する\n",
    "room = pa.ShoeBox(room_dim, fs=sample_rate, max_order=0)\n",
    "\n",
    "# 用いるマイクロホンアレイの情報を設定する\n",
    "room.add_microphone_array(pa.MicrophoneArray(R, fs=room.fs))\n",
    "\n",
    "# 音源の場所\n",
    "doas = np.array(\n",
    "    [[np.pi/2., 0]]\n",
    ")\n",
    "\n",
    "# ↑音源は1つなので1個\n",
    "\n",
    "# 音源とマイクロホンの距離\n",
    "distance = 1\n",
    "\n",
    "source_locations = np.zeros((3, doas.shape[0]), dtype=doas.dtype)\n",
    "source_locations[0, :] = np.cos(doas[:, 1]) * np.sin(doas[:, 0])\n",
    "source_locations[1, :] = np.sin(doas[:, 1]) * np.sin(doas[:, 0])\n",
    "source_locations[2, :] = np.cos(doas[:, 0]) \n",
    "source_locations *= distance\n",
    "source_locations += mic_array_loc[:, None]\n",
    "\n",
    "print(np.shape(clean_data))\n",
    "\n",
    "# 各音源をシミュレーションに追加する\n",
    "for s in range(n_sources):\n",
    "    clean_data[s] /= np.std(clean_data[s])\n",
    "    room.add_source(source_locations[:, s], signal=clean_data[s])\n",
    "\n",
    "# シミュレーションを回す\n",
    "room.simulate(snr=SNR)\n",
    "\n",
    "# 畳み込んだ波形を取得する（チャンネル、サンプル）\n",
    "multi_conv_data = room.mic_array.signals\n",
    "\n",
    "write_file_from_time_signal(multi_conv_data[0] * np.iinfo(np.int16).max/20., \"./mix_in.wav\", sample_rate)\n",
    "\n",
    "far_steering_vectors = calculate_steering_vector(R, source_locations=source_locations, freqs=freqs, is_use_far=True)\n",
    "\n",
    "# 短時間フーリエ変換を行う\n",
    "f, t, stft_data = sp.stft(multi_conv_data, fs=sample_rate, window=\"hann\", nperseg=N)\n",
    "\n",
    "# 遅延和アレイを実行する\n",
    "s_hat = np.einsum(\"ksm,mkt->skt\", np.conjugate(far_steering_vectors), stft_data)\n",
    "\n",
    "c_hat = np.einsum(\"skt,ksm->mskt\", s_hat, far_steering_vectors)\n",
    "\n",
    "# 時間領域の波形に戻す\n",
    "t, ds_out = sp.istft(c_hat[0], fs=sample_rate, window=\"hann\", nperseg=N)\n",
    "\n",
    "# 大きさを調整する\n",
    "ds_out = ds_out*np.iinfo(np.int16).max/20.\n",
    "\n",
    "# ファイルに書き込む\n",
    "write_file_from_time_signal(ds_out, \"./ds_out.wav\", sample_rate)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 2)\n"
     ]
    }
   ],
   "source": [
    "# 方向をスキャンするコードを生成\n",
    "# マイクの位置を0としたシミュレーションの音声波形を生成\n",
    "# スキャンしたスペクトルを描画->スペクトルはどの値をとる？\n",
    "#    ->音のアレイ信号処理 p.103より、スペクトルはステアリング方向を変化させたときの各角度についての平均出力パワーをスペクトルとすればいいらしい。\n",
    "import numpy as np\n",
    "\n",
    "angles = np.linspace(-np.pi, np.pi, 20)\n",
    "angles = np.hstack((angles[:, None], np.zeros((angles.size, 1))))\n",
    "print(angles.shape)\n",
    "\n",
    "# doas = np.array()\n",
    "\n",
    "sample_rate = 16000\n",
    "N = 1024 # フレームサイズ\n",
    "\n",
    "multi_conv_data = room.mic_array.signals # 時間領域でデータを取得 shapeは(M, 時間インデックス数)\n",
    "\n",
    "f,t,stft_data = sp.stft(multi_conv_data, fs=sample_rate, window=\"hann\", nperseg=N)\n",
    "\n",
    "# スペクトル生成のためのフレーム数\n",
    "frame_num = 10\n",
    "\n",
    "multi_conv_data_inv = np.transpose(multi_conv_data, axes=(1, 0, 2)).conj()\n",
    "\n",
    "set_index = 1\n",
    "while True:\n",
    "    mean_start_index = (set_index-1)*frame_num\n",
    "    mean_end_index = set_index*frame_num\n",
    "    \n",
    "    if mean_start_index >= multi_conv_data.shape[2]:\n",
    "        break\n",
    "    if mean_end_index > multi_conv_data.shape[2]:\n",
    "        mean_end_index = multi_conv_data.shape[2]\n",
    "    \n",
    "    zz = np.einsum(\"mkt,knt->mn\", multi_conv_data[:, :, mean_start_index:mean_end_index], multi_conv_data_inv[:, :, mean_start_index:mean_end_index]) / frame_num\n",
    "    \n",
    "    for (\"各方向をスキャンする処理\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
